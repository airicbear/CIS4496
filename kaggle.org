#+TITLE: I'm Something of a Painter Myself
#+SUBTITLE: Use GANs to create art - will you be the next Monet?

* Overview

** Description

#+begin_quote
"Every artist dips his brush in his own soul, and paints his own nature into his pictures."

---Henry Ward Beecher
#+end_quote

We recognize the works of artists through their unique style, such as color choices or brush strokes.
The "je ne sais quoi" of artists like Claude Monet can now be imitated with algorithms thanks to generative adversarial networks (GANs).
In this getting started competition, you will bring that style to your photos or recreate the style from scratch!

Computer vision has advanced tremendously in recent years and GANs are now capable of mimicking objects in a very convincing way.
But creating museum-worthy masterpieces is thought of to be, well, more art than science.
So can (data) science, in the form of GANs, trick classifiers into believing you've created a true Monet?
That's the challenge you'll take on!

*** The Challenge

A GAN consists of at least two neural networks: a generator model and a discriminator model.
The generator is a neural network that creates the images.
For our competition, you should generate images in the style of Monet.
This generator is trained using a discriminator.

The two models will work against each other, with the generator trying to trick the discriminator, and the discriminator trying to accurately classify the real vs. generated images.

Your task is to build a GAN that generates 7,000 to 10,000 Monet-style images.

*** Getting Started

Details on the dataset can be found [[https://www.kaggle.com/c/gan-getting-started/data][here]] and an overview of the evaluation process can be found [[https://www.kaggle.com/c/gan-getting-started/overview/evaluation][here]].

To learn how to submit and answers to other FAQs, review the [[https://www.kaggle.com/c/gan-getting-started/overview/frequently-asked-questions][Frequently Asked Questions]].

#+begin_comment
*Recommended Tutorial*

We highly recommend [[https://www.kaggle.com/amyjang/monet-cyclegan-tutorial][Amy Jang's notebook]] that goes over the basics of loading data from TFRecords, using TPUs, and building a CycleGAN.
#+end_comment

Although the competition dataset only includes Monet images, check out this [[https://github.com/junyanz/CycleGAN][dataset]] for Cezanne, Ukiyo-e, and Van Gogh paintings to run your GAN on.

** Evaluation

*** MiFID

Submissions are evaluated on MiFID (Memorization-informed Fréchet Inception Distance), which is a modification from [[https://arxiv.org/abs/1706.08500][Fréchet Inception Distance (FID)]].

The smaller MiFID is, the better your generated images are.

*** What is FID?

Originally published [[https://arxiv.org/abs/1706.08500][here]] ([[https://github.com/bioinf-jku/TTUR][github]]), FID, along with [[https://arxiv.org/abs/1606.03498][Inception Score (IS)]], are both commonly used in recent publications as the standard for evaluation methods of GANs.

In FID, we use the Inception network to extract features from an intermediate layer.
Then we model the data distribution for these features using a multivariate Gaussian distribution with mean μ and covariance Σ.
The FID between the real images \(r\) and generated images \(g\) is computed as

\[\text{FID} = \|\mu_r - \mu_g\|^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})\]

where \(\text{Tr}\) sums up all the diagonal elements.
FID is calculated by computing the Fréchet distance between two Gaussians fitted to feature representations of the Inception network.

*** What is MiFID (Memorization-informed FID)?

In addition to FID, Kaggle takes training sample memorization into account.

The memorization distance is defined as the minimum cosine distance of all training samples in the feature space, averaged across all user generated image samples.
This distance is thresholded, and it's assigned to 1.0 if the distance exceeds a pre-defined epsilon.

In mathematical form:

\[d_{ij} = 1 - \cos(f_{gi}, f_{rj}) = 1 - \frac{f_{gi} \cdot f_{rj}}{|f_{gi}||f_{rj}|}\]

where \(f_g\) and \(f_r\) represent the generated/real images in feature space (defined in pre-trained networks); and \(f_{gi}\) and \(f_{rj}\) represent the \(i^{th}\) and \(j^{th}\) vectors of \(f_g\) and \(f_r\), respectively.

\[d = \frac{1}{N} \sum_i \min_j d_{ij}\]

defines the minimum distance of a certain generated image (\(i\)) across all real images (\(j\)), then averaged across all the generated images.

\[d_{thr} = \begin{cases} d, &\text{if } d < \epsilon \\ 1, &\text{otherwise}\]

defines the threshold of the weight only applies when the (\(d\)) is below a certain empirically determined threshold.

Finally, this memorization term is applied to the FID:

\[MiFID = FID \cdot \frac{1}{d_{thr}}\]

*** Kaggle's workflow calculating MiFID for public and private scores

Kaggle calculates public MiFID scores with the pre-train neural network [[http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz][Inception]], and the public images used for evaluation are the rest of the TFDS Monet paintings.
*Note that as a Getting Started competition there is no private leaderboard.*

A demo of our MiFID evaluation code can be seen [[https://www.kaggle.com/wendykan/demo-mifid-metric-for-dog-image-generation-comp][here]].

*** Submission File

You are going to generate 7,000-10,000 Monet-style images that are in =jpg= format.
Their sizese should be 256×256×3 (RGB).
Then you need to zip those images and your output from your Kernel should only have ONE output file named =images.zip=.

Please note that Kaggle Kernels has a number of output files capped at 500.
We highly encourage you to either directly write to a =zip= file as you generate images, or create a folder at =../tmp= as your temporary directory.

** Prizes

*** Are you a TPU Star?

For this competition, we are offering an opportunity to be awarded one of 3 "TPU Star" Prizes to the most knowledgeable and helpful TPU experts in the community.
The winners will receive an extra 20 hours per week of TPU time on Kaggle for four weeks.

*** How to win?

"TPU Star" award will be evaluated by experts from the Google Cloud TPU team, on the following criteria:

- Forum and notebook discussion/comment contributions

- Quality of code samples in public notebooks and/or forums

- Thoughtful analysis and explainability of code content

*** How do I enter?

You may become eligible for these prizes either of two ways:

1. Kaggle-identified: Kaggle will query all participants in the competition contributing upvoted public notebook(s) and making discussion contribution(s).

2. Self-nominated: [[https://www.kaggle.com/tpu-star-submission-painter][Submit this form]] to self-nominate for consideration.
   At a minimum, you must have shared a public notebook which uses Kaggle's TPU integration on this competition's dataset.
   Please wait to make your self-nomination submission until you have created and shared the public content that supports your nomination.

The deadline for self-nomination is *October 31, 2020*.

** Code Requirements

Submissions to this competition must be made by an output from a Kaggle Notebook/Script.

** Frequently Asked Questions

* Data
